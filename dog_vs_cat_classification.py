# -*- coding: utf-8 -*-
"""DogsVsCatsClassificationAndSaveModelToReuseInFuture.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wX7wh3bGxmPb304P6WrvJfOyEzdQA1J_

# Create a Model to Classify Cats and Dogs and Save Best Model to reuse in Future.

## Specific Concept that will be covered.

In this process, I'll build practical experience and develop intution around the following concept

- Building data input pipelines using the `tf.keras.preprocessing.image.ImageDataGenerator` class. How can I efficiently work with data on disk to interface with our model?
- Overfitting - what is it?, how to identify it, and how can we prevent it?
- Data Augmentation and Dropout - key techniques to fight overfitting in computer vision tasks that I'll incorporate into data pipeline and image classifier model.

## I'll follow the general machine learning workflow.

1. Examine and understand data
2. Buid an input pipeline
3. Buil my model
4. Train my model
5. Test my model
6. Improve my model/Repeat the process
7. Save my best model

## Importing Packages
"""

import tensorflow as tf

from tensorflow.keras.preprocessing.image import ImageDataGenerator

import os
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime

"""## Download Data and read data from given URL

To build image classifier, I begine by downloading the dataset. The daset I'm using a fitered version of [Dogs vs. cats](https://www.kaggle.com/c/dogs-vs-cats/data) dataset from kaggle (ultimately, this dataset is provided by Microsoft Research). I'll use ImageDataGenerator from  `tf.keras.preprocessing.image.ImageDataGenerator` which read data from disk.
"""

_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'

zip_dir = tf.keras.utils.get_file('cats_and_dogs_filtered.zip', origin = _URL, extract=True)

"""## Read dataset from directory """

base_dir = os.path.join(os.path.dirname(zip_dir), 'cats_and_dogs_filtered')

train_dir = os.path.join(base_dir, 'train')
validation_dir = os.path.join(base_dir, 'validation')

train_cats_dir = os.path.join(train_dir, 'cats')
train_dogs_dir = os.path.join(train_dir, 'dogs')

validation_cats_dir = os.path.join(validation_dir, 'cats')
validation_dogs_dir = os.path.join(validation_dir, 'dogs')

num_cats_tr = len(os.listdir(train_cats_dir))
num_dogs_tr = len(os.listdir(train_dogs_dir))

num_cats_val = len(os.listdir(validation_cats_dir))
num_dogs_val = len(os.listdir(validation_dogs_dir))

total_train = num_cats_tr + num_dogs_tr
total_validation  = num_cats_val + num_dogs_val

"""## Understanding Data"""

print(f'total training cats images: {num_cats_tr}')
print(f'total training dogs images: {num_dogs_tr}')

print(f'total validation cats images: {num_cats_val}')
print(f'Toatal validation dogs images: {num_dogs_val}')

print(f'Total training images: {total_train}')
print(f'Total validation images: {total_validation}')

"""## Setting Model's Parametrs"""

BATCH_SIZE = 100
IMG_SHAPE = 150

"""## Data Augmentation

Overfitting often occure when we have a small number of training examples. One way to fix this problem is to augment our datset so that it has sufficient number and variety of training examples. Data augmentation takes the approach of generating more training dataset from existing traning samples by augmenting the samples through random transformation that yield believable-looking images. The goal is that at training time, my model will never see the exact same picture twice. This exposes the model to more aspects of the dats, allowing it to genralize better.

In `tf.keras` I can implement this using the same **imageDataGenerator** class I used before. I can simply pass difference transformations I would want to my dataset as form of augmentations and it'll take care of applying it to the dataset duraning training process.
"""

def plotImage(images_arr):
  fig, axes = plt.subplots(1, 5, figsize=(20, 20))
  axes = axes.flatten()
  for img, ax in zip(images_arr, axes):
    ax.imshow(img)
  plt.tight_layout()
  plt.show()

"""### Flipping the image horizontally"""

image_gen = ImageDataGenerator(rescale=1/255, horizontal_flip=True)

train_data_gen = image_gen.flow_from_directory(batch_size=BATCH_SIZE,
                                               directory=train_dir,
                                               shuffle=True,
                                               target_size=(IMG_SHAPE, IMG_SHAPE))

augmented_images = [train_data_gen[0][0][0] for i in range(5)]
plotImage(augmented_images)

"""### Rotating the image"""

image_gen = ImageDataGenerator(rescale=1/255, rotation_range=45)
train_data_gen = image_gen.flow_from_directory(batch_size=BATCH_SIZE,
                                               directory=train_dir,
                                               shuffle=True,
                                               target_size=(IMG_SHAPE, IMG_SHAPE))

augmented_images = [train_data_gen[0][0][0] for i in range(5)]
plotImage(augmented_images)

"""### Putting it all together"""

image_gen_train = ImageDataGenerator(
        rescale=1/255,
        rotation_range=45,
        width_shift_range=0.2,
        height_shift_range=0.2,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True,
        fill_mode='nearest')

train_data_gen = image_gen_train.flow_from_directory(batch_size=BATCH_SIZE,
                                                     directory=train_dir,
                                                     shuffle=True,
                                                     target_size=(IMG_SHAPE, IMG_SHAPE),
                                                     class_mode='binary')

augmented_images = [train_data_gen[0][0][0] for i in range(5)]
plotImage(augmented_images)

"""## Creating Validation Data Generatation"""

image_gen_val = ImageDataGenerator(rescale=1./255)

val_data_gen = image_gen_val.flow_from_directory(batch_size=BATCH_SIZE,
                                                 directory=validation_dir,
                                                 target_size=(IMG_SHAPE, IMG_SHAPE),
                                                 class_mode='binary')

"""## Create Model

### Define the model

The model consist of four convolution blocks with a max pool layer in each of them.

Before the final dense layer, we're also applying a Dropout problility of 0.5. It means that 50% of the values coming into the Dropout layer will be set to zero. This helps to prevent overfitting.

Then we've a fully connected layer with 512 units, with `relu` activation function. The model will output class probabilities for two classes **dogs and cats** using `softmax`.
"""

model = tf.keras.models.Sequential([
                                    
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),

    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),

    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),

    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),

    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(2, activation='softmax')
])

"""### Compiling the model

As usual, I will use the `adam` optimizer. Since I output a softmax categorization, I'll use `sparse_categorical_crossentropy` as the loss function. I would also like to look at training and validation accuracy on each epoch as I train my network, so I'm passing in the metrics argument.
"""

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

"""## Model Summary"""

model.summary()

"""## Train the model 

It's time I train my network.

Since my batches are coming from a generator (`ImageDataGenerator`), I'll use `fit_generator` instead of `fit`.
"""

epochs=100
history = model.fit_generator(
      train_data_gen,
      steps_per_epoch=int(np.ceil(total_train / float(BATCH_SIZE))),
      epochs=epochs,
      validation_data=val_data_gen,
      validation_steps=int(np.ceil(total_validation / float( BATCH_SIZE)))
      )

"""## Visualizing result of training """

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(epochs)

plt.figure(figsize=(20, 10))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label = "Validation Accuracy")
plt.legend(loc='lower right')
plt.title('Trainig and Validation Accuracy')


plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

image_batch, label_batch = next(iter(train_data_gen))

predicted_batch = model.predict(image_batch)
predicted_batch = tf.squeeze(predicted_batch).numpy()
predicted_batch = np.argmax(predicted_batch, axis=-1)

"""### Label
- 1 for Dog

- 0 for cat
"""

print(f'Actual Labels: {label_batch[:20]}')
print(f'Predicted Label: {predicted_batch[:20]}')

plt.figure(figsize=(10, 9))
for n in range(30):
  plt.subplot(6, 5 , n+1)
  plt.imshow(image_batch[n])
  color = 'blue'if predicted_batch[n] == label_batch[n] else 'red'
  plt.title(predicted_batch[n], color=color)
  plt.axis('off')
  _=plt.suptitle("model predictions(blue: correct, red:- incorrect)")

"""## Save Model"""

#!pwd

# Commented out IPython magic to ensure Python compatibility.
# %cd drive/MyDrive/Colab\ Notebooks

#!pwd

now = datetime.now()

export_path_sm = './{}'.format(now.strftime('SaveMode/%d-%m-%Y-%H:%M:%S'))
print(export_path_sm)

tf.saved_model.save(model, export_path_sm)

"""### I've save model as `saved_model.pb`"""

ls {export_path_sm}

reloaded_sm = tf.saved_model.load(export_path_sm)

reloaded_sm_result_batch = reloaded_sm(image_batch, training=False).numpy()
result_batch = tf.squeeze(reloaded_sm_result_batch).numpy()
result_batch = np.argmax(result_batch, axis=-1)

abs(predicted_batch - result_batch).max()

"""## Download to local disk"""

zip -r model.zip {export_path_sm}

try:
  from google.colab import files
  files.download('./model.zip')
except ImportError:
    pass







